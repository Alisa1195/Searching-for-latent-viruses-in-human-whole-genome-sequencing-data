---
title: "Lab_report_ILI_Genotek"
author: "Yura Orlov, Nadya Pogodina, Alisa Morshneva"
date: "23 05 2019"
output:
  html_document: default
  pdf_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
__At the start of the project, we faced a challenge of developing a pipeline for fast viral load and representation assessment in multiple samples. The test WGS sample (raw reads) of  uterine tissue of a woman with cervical canser provided by Genotek was used for creating and testing pipeline. We pre-processed the data, aligned reads to the reference, extracted unmapped reads and then compared different methods of viruses identification (BLAST, Kraken):__

### Pre-processing

#### Deduplication + adapter trimming

`~/tools/bbmap/clumpify.sh in1=~/data/HPV/raw/mv8970.82B476AA6.1.fastq.gz in2=~/data/HPV/raw/mv8970.82B476AA6.2.fastq.gz out1=F_dedup.fastq.gz out2=R_dedup.fastq.gz dedupe`
	
##### Summary: <br />
Reads In:        	101449352 <br />
Clumps Formed:    	26582955 <br />
Duplicates Found:  	5110424 <br />
Reads Out:        	96338928 <br />
Bases Out:      	9730231728 <br />
Total time:     2892.103 seconds <br />

TruSeq adapter trimming, deleting “N”s on the ends and discarding reads with total “N” fraction more than 50% <br />

cutadapt <br />
 --trim-n <br />
 --max-n 0.5 <br />
 --minimum-length 20 <br />
 -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCACAGCGATAGATCTCGTAT -A <br /> AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTTCAGAGCCGTGTAGATCT <br />
-o F_dedup_tr1.fastq.gz <br />
-p R_dedup_tr1.fastq.gz <br />
F_dedup.fastq.gz R_dedup.fastq.gz <br />

Total read pairs processed: 48,169,464 <br />
Read 1 with adapter:       	5,087,541 (10.6%) <br />
Read 2 with adapter:       	4,083,942 (8.5%) <br />
Pairs that were too short:  1,083,475 (2.2%) <br />
Pairs with too many N:      1,049 (0.0%) <br />
Pairs written <br />
(passing filters):          47,084,940 (97.7%)<br />


(AT)n sequence trimming
	
cutadapt 
-minimum-length 16
-a ATATATATATATATATATATATATATATATATATATATATATATATATAT
-A ATATATATATATATATATATATATATATATATATATATATATATATATAT <br /> 
-o F_dedup_tr2.fastq.gz <br />
-p R_dedup_tr2.fastq.gz <br />
F_dedup_tr1.fastq.gz R_dedup_tr1.fastq.gz

Total read pairs processed:          47,084,940 <br />
Read 1 with adapter:           	     2,564,340 (5.4%) <br />
Read 2 with adapter:           	     2,182,251 (4.6%) <br />
Pairs that were too short:           1,451,924 (3.1%) <br />
Pairs written (passing filters):     45,633,016 (96.9%) <br />



One more TruSeq adapter trimming and quality trimming 

cutadapt 
-minimum-length 16 
-q 30,30
--pair-filter=any <br />
-a AGATCGGAAGAGCACACGTCTGAACTCCAGTCACAGCG <br />
-o F_dedup_tr5.fastq.gz <br />
-p R_dedup_tr5.fastq.gz <br />
F_dedup_tr2.fastq.gz R_dedup_tr2.fastq.gz <br />

Pairs written (passing filters):    40,198,889 (88.4%)



__Pipeline:__ <br />
Adapter trimming and quality trimming
`cutadapt --interleaved --trim-n --max-n 0.5 -m 20 -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCACAGCGATAGATCTCGTAT -A AGATCGGAAGAGCGTCGTGTAGGGAAAGAGTGTTCAGAGCCGTGTAGATCT input.1.fastq.gz input.2.fastq.gz | cutadapt --interleaved -m 20 -a ATATATATATATATATATATATATATATATATATATATATATATATATAT -A ATATATATATATATATATATATATATATATATATATATATATATATATAT - | cutadapt --interleaved -m 20 -a AGATCGGAAGAGCACACGTCTGAACTCCAGTCACAGCG - | cutadapt --interleaved -m 20 -q 30,30 -o F_output.fastq.gz -p R_output.fastq.gz -`

`/home/orlov239/tools/bbmap/clumpify.sh \
in1=F_output.fastq.gz \
in2=R_output.fastq.gz \
out1=F_dedup_output.fastq.gz \
out2=R_dedup_output.fastq.gz dedupe`

### Alignment of the WGS data to the reference

at first we chose __GRCh38 (2013)__ as a reference <br />

Then, there are different strategies: <br />
1) use GRCh37 - less full and doesn't include EBV. <br />
One the one hand, we don't need the precise accuracy of the assembly - we are interested in another part of the data - unmapped reads. One the other hand, the less reads are left after alignment, the faster and easier we perform the further steps. <br />
2) use one of GRCh38 releases and then extract mapped to EBV reads <br />
3) “make” our own reference by exctraction of EBV out of GRCh38 assembly

#### Indexing of the reference

`bwa index /home/g1195alisa/GRCh38_2013/GCA_000001405.15_GRCh38_genomic.fna`

#### Alignment of paired-end reads to the reference

`bwa mem -t 6 /home/g1195alisa/GRCh38_2013/GCA_000001405.15_GRCh38_genomic.fna /home/orlov239/data/HPV/processed/F_dedup_tr5.fastq.gz /home/orlov239/data/HPV/processed/R_dedup_tr5.fastq.gz`

Alignment took almost 4 hours to be finished (6 threads), resulting in sam-файл of 25Gb 

#### Conversion to bam

`samtools view -S -b alignment_test_3.sam > alignment_test_3.bam`

file has shrinked to 8Gb

__The test alignment statistics__

samtools flagstat alignment_test_3.bam

output: <br />
83078254 + 0 in total (QC-passed reads + QC-failed reads)<br />
0 + 0 secondary<br />
2680476 + 0 supplementary<br />
0 + 0 duplicates<br />
80958206 + 0 mapped (97.45% : N/A)<br />
80397778 + 0 paired in sequencing<br />
40198889 + 0 read1<br />
40198889 + 0 read2<br />
68079812 + 0 properly paired (84.68% : N/A)<br />
77566460 + 0 with itself and mate mapped<br />
711270 + 0 singletons (0.88% : N/A)<br />
7094860 + 0 with mate mapped to a different chr <br />
4864885 + 0 with mate mapped to a different chr (mapQ>=5) <br />

The percentage of mapped reads is suspiciously high, almost 100%, but if we look at amount of reads, about 2 millions of reads have been left unmapped

#### Extraction of unmapped reads

`samtools view -b -f 4 alignment_test_3.bam > unmapped_test.bam (single-end)`
 
To get paired-end:

__R1 & R2 unmapped__

`samtools view -u -f 12 -F 256 alignment_test_sorted.bam > f1_unmap_unmap.bam`

#### Resulting pipeline:
1) align + convert to bam + sort

`bwa mem -t 16 /home/g1195alisa/GRCh38_2013/GCA_000001405.15_GRCh38_genomic.fna /home/orlov239/data/HPV/processed/F_dedup_tr5.fastq.gz /home/orlov239/data/HPV/processed/R_dedup_tr5.fastq.gz | samtools view -S -@ 16 -b | samtools sort -@ 16 -o alignment_sorted.bam.gz`

2) extract unmapped reads <br />

------

3) Convert bam to fastq

`samtools bam2fq f1_unmap_unmap.bam > unmap_unmap.fastq`

*Summary of the alignment step: the speed needs improvement, some commands should be combined for convenience.*

### De novo assembly

The study of Moustafa et. al, 2017 compares results of the BLAST and de novo asembly. We decided to skip the assembly, because it takes a lot of time, considering the fact we needed to analyse hundreds of genomes

`spades.py --meta --only-assembler -12 /input.fastq -o ./output_folder/`
“scaffolds.fasta”


### Alignment of reads in blast.
We've got unmapped reads (fastq). Next, we should convert them to fasta

`$ paste - - - - < unmapped_test.fastq | cut -f 1,2 | sed 's/^@/>/' | tr "\t" "\n" > /home/nadya379/unmapped_reads.fasta`
The other convertation method <br />   https://www.ecseq.com/support/ngs-snippets/convert-fastq-to-fasta-on-the-command-line <br />

#### Downloading of the reference, making the database
Link to the reference: NCBI ftp://ftp.ncbi.nlm.nih.gov/blast/db/ <br />
For viruses: ref_viruses_rep_genomes. Plus, ref_prok_rep_genomes and vector should be downloaded. <br />
To get the result with taxonomical names for each read we need to download the database and specify the path: <br />
`$ ./update_blastdb.pl taxdb`
`$ mv taxdb* ../blastdb/`
`$ cd blastdb`
`$ tar -xzvf taxdb.tar.gz  (распаковка сразу нескольких архивов cat *.tar.gz | tar -xzvf - -i)`
`$ rm taxdb.tar.gz`
`$ export BLASTDB=$BLASTDB:/home/nadya379/ncbi-blast-2.8.1+/blastdb/`

Combine three databases <br />
`$ blastdb_aliastool -dblist "ref_viruses_rep_genomes ref_prok_rep_genomes vector" -dbtype nucl \ -out vir_prok_vec -title "Viruses, prok and vectors" `

Launch BLAST <br />
Info about some flags in blastn https://www.ncbi.nlm.nih.gov/books/NBK279684/ 
Launched the alignment
`$ blastn -query ../unmapped_reads.fasta -db blastdb/vir_prok_vec -out ../align_to_viral_ref -outfmt '6 qseqid sseqid pident nident length mismatch evalue bitscore sscinames sskingdoms’ -evalue 1e-10`

Specify the E-value threshold. Used the one from the article (Moustafa, 2017). If use default 10, get a lot of “0 hits found” <br />

`$ cut -f 10 ../align_to_vir_prok_vec | sort | uniq -c`
2453 Archaea<br />
3061153 Bacteria <br />
1983107 N/A <br />
29028 Viruses <br />

Extract only viruses, then extract only unique reads and make the database
`$ grep Viruses ../align_to_vir_prok_vec | sort -u -k1,1 | cut -f 1,11 | awk '{printf(">%s\n%s\n", $1, $2); }' > ../viruses_after_first_align.fasta`

We've got 11620 reads <br />
Get read names we need:
`$paste - - - - < ../viruses_after_first_align.fasta | cut -f 1 | sed 's/^@/>/' | tr "\t" "\n" > ../reads_viruses`

Remove unnecessary characters
`$cat ../reads_viruses.txt | cut -c2- > ../reads_viruses`

Search for these reads in fasta file
`$perl -ne 'if(/^>(\S+)/){$c=$i{$1}}$c?print:chomp;$i{$_}=1 if @ARGV' ../reads_viruses ../unmapped_reads.fasta > ../viruses_after_align.fasta`

Make a dataframe for the further filtration 
`$ cut -f 1,8,9,10 ../align_to_vir_prok_vec > ../for_R.csv`

Repeat in R, using dplyr.The code: `ССЫЛКА НА ГИТ`

__The point is, we group by reads, then search for the maximum bitscore in groups and get unique reads, among which we search for the viruses.__ <br />
We've got 10164 reads, weach is less than after a direct search of all mapped to viruses reads. <br />

We could try to align these reads to rafseq_genomic, to exclude false alignments
`$ blastn -query ../viruses_after_align.fasta -db blastdb/refseq_genomic -out ../align_to_all_ref -outfmt '6 qseqid sseqid pident nident length mismatch evalue bitscore sscinames sskingdoms' -evalue 1e-20 -num_threads 8`
Doesn't work... <br />

Try Blat (installation http://genomic-identity.wikidot.com/install-blat) <br />
Blat takes fasta files. Download: <br /> https://ftp.ncbi.nlm.nih.gov/refseq/release/complete/ <br />
Merge to one file: `$ cat *.fna >> all_ref_seq.fasta`
Blat doesn't work with this database either. We decided to use only the first database (prokaryotes, vectors and viruses)

### Launch of kraken2 
https://ccb.jhu.edu/software/kraken2/

Used a standart RefSeq database (~40 Gb):

`kraken2-build --standard --threads 7 --db ./databases/standart`

Analysed our data:
`kraken2 --fastq-input --use-names --db ./databases/standart --threads 7 --output ~/data/HPV/reports/kraken2/1st_try/kraken_output --classified-out ~/data/HPV/reports/kraken2/1st_try/kraken_output_clssified_seq.fastq --unclassified-out ~/data/HPV/reports/kraken2/1st_try/kraken_output_unclssified_seq.fastq /home/unmapped_reads/unmapped_test.fastq `

Report:
2120048 sequences (173.79 Mbp) processed in 5.344s (23802.4 Kseq/m, 1951.19 Mbp/m). <br />
306588 sequences classified (14.46%) <br />
1813460 sequences unclassified (85.54%) <br />

Out of 306588 classified sequences about 12000 belong to viral ones (parsing of kraken_output file with awk and grep  (“vir”), 7000 (awk and grep either) belong to HPV.


The same for assembled metagenome:
`kraken2 --use-names --db ./databases/standart --threads 7 --output ~/data/HPV/reports/kraken2/1st_try/kraken_output_assembled --classified-out ~/data/HPV/reports/kraken2/1st_try/kraken_output_assembled_classified_seq.fa --unclassified-out ~/data/HPV/reports/kraken2/1st_try/kraken_output_assembled_unclassified_seq.fa /home/orlov239/data/HPV/assembled/1st_attempt/scaffolds.fasta`

9738 sequences (2.97 Mbp) processed in 0.607s (963.2 Kseq/m, 293.92 Mbp/m).<br />
6230 sequences classified (63.98%)<br />
3508 sequences unclassified (36.02%)<br />
 
10 viral sequences:

4 на HPV type 16<br />
6 на Human mastadenovirus C<br />



## 8000 Viromes 
tested pipeline at the data from the article Moustafa et.al 

__BLAST__
`$ cat *.fa > /home/nadya379/all_virome_queries.fa`
`$ blastn -query ../all_virome_queries.fa -db blastdb/vir_prok_vec -out ../Moustafa_output -outfmt '6 qseqid sseqid pident nident length mismatch evalue bitscore sscinames sskingdoms' -evalue 1e-20 -num_threads 8`
`$ cut -f 10 ../Moustafa_output | sort | uniq -c`

1 Archaea <br />
141 Bacteria <br />
18 N/A <br />
6507 Viruses <br />

__Kraken__

https://genomics.sschmeier.com/ngs-taxonomic-investigation/index.html


`$ kraken2 --fasta-input --use-names --db ./databases/standart --threads=8 --output /home/g1195alisa/kraken_reports/kraken_output_all --classified-out /home/g1195alisa/kraken_reports/kraken_output_clssified_all.fa --unclassified-out /home/g1195alisa/kraken_reports/kraken_output_unclssified_all.fa --report /home/g1195alisa/kraken_reports/kraken_output_report_all  /home/nadya379/Moustafa/all_virome_queries.fa `

Output files:<br />
kraken_output_all<br />
kraken_output_clssified_all<br />
kraken_output_unclssified_all<br />
kraken_output_report_all 


__Taxonomic classification in the "report" file (kraken_output_report_all ):__

1. Percentage of reads covered by the clade rooted at this taxon<br />
2. Number of reads covered by the clade rooted at this taxon<br />
3. Number of reads assigned directly to this taxon<br />
4. A taxonomy rank code<br />
5. NCBI taxonomy ID<br />
6. indented scientific name<br />

We could analyse the representation of different taxones:
`$ cut -f 3 ./kraken_output_all_1 | sort | uniq -c | sort -n -r`

  The figures at the end of lines represent what place the virus takes in original article <br />
   1167 Human gammaherpesvirus 4 (taxid 10376) 2 (1190/8000)* <br />
   1082 Rhizobium phage RR1-B (taxid 929834)<br />
     62 Human betaherpesvirus 7 (taxid 10372) 1 (1678/8000)<br />
     48 unclassified (taxid 0)<br />
     43 root (taxid 1)<br />
     31 Brucella sp. 09RB8471 (taxid 1149952) <br />
     21 Burkholderia pseudomallei (taxid 28450) ? <br />
     13 Burkholderia virus Bcep22 (taxid 242527) ? <br />
     11 Ralstonia pickettii 12D (taxid 428406) <br />
     10 Torque teno virus 12 (taxid 687351) 3 <br />
     10 Alphatorquevirus (taxid 687331) <br />
      7 Pa6virus (taxid 1982251) <br />
      6 Shinella sp. HZN7 (taxid 879274) <br />
      6 Ralstonia solanacearum Rs-10-244 (taxid 1457195) <br />
      5 Torque teno virus 2 (taxid 687341) 3 <br />
      5 Torque teno virus 15 (taxid 687354) 3 <br />
      5 Torque teno virus 13 (taxid 687352) 3 <br />
      5 Human herpesvirus 4 type 2 (taxid 12509) 2 <br />
      5 Chromobacterium rhizoryzae (taxid 1778675) <br />
      5 blood disease bacterium A2-HR MARDI (taxid 1944648) <br />
      4 Human betaherpesvirus 6B (taxid 32604) 4 (395/8000) <br />
      3 Torque teno virus 3 (taxid 687342) 3 <br />
      3 Ralstonia insidiosa (taxid 190721) <br />
      3 Brucella sp. 141012304 (taxid 1885919) <br />
      2 Sinorhizobium phage PBC5 (taxid 179237) <br />
      2 Sindbis virus (taxid 11034) <br />
      2 Pseudomonas (taxid 286) <br />
      2 Propionibacterium phage PHL010M04 (taxid 1235645) <br />
      1 unclassified Enterobacteriaceae (miscellaneous) (taxid 36866) <br />
      1 Torque teno virus 6 (taxid 687345) 3 <br />
      1 Torque teno virus 4 (taxid 687343) 3 <br />
      1 Torque teno virus 10 (taxid 687349) 3 <br />
      1 Streptomyces sp. CMB-StM0423 (taxid 2059884) <br />
      1 Rhizobium sp. IRBG74 (taxid 424182) <br />
      1 Ralstonia (taxid 48736) <br />
      1 Ralstonia solanacearum (taxid 305) <br />
      1 Ralstonia solanacearum FJAT-1458 (taxid 1130828) <br />
      1 Propionibacterium phage QueenBey (taxid 1654782) <br />
      1 Propionibacterium phage PHL171M01 (taxid 1500827) <br />
      1 Propionibacterium phage PHL025M00 (taxid 1500799) <br />
      1 Propionibacterium phage P104A (taxid 1229787) <br />
      1 Propionibacterium phage BruceLethal (taxid 1654740)<br />
      1 Moloney murine leukemia virus (taxid 11801)<br />
      1 Escherichia coli (taxid 562) <br />
      1 Altererythrobacter namhicola (taxid 645517) <br />
      1 Alphaproteobacteria (taxid 28211)<br />

*We've got  Human gammaherpesvirus 4 at the top, but it's a high-copy virus, so it's just a smal selection effect <br />

#### Tasks:
1) Find out how to analyse a lot of genomes in a time: made the bash script <br />
2) Get report zero -use-map-style statistics - done <br />
3) Ectract only viruses (SRR) - done <br />
4) Split reads by the launch ID (RG) - done <br />

### Testing of WGS samples from Genotek

extraction of unmapped reads 
`samtools view -f 4 ./raw_data/zd3089_clipped.bam > ./zd3089_unmap.bam` 
conversion to fastq
`for f in *_unmap.bam; do filename="${f%%.*}"; samtools bam2fq -@ 6 $f > ${fil
ename}.fastq; done`
Kraken2 
`for f in *_unmap.fastq; do filename="${f%%.*}"; kraken2 --use-names --db /home/orlov239/tools/kraken2/databases/standart --threads=8 --report /home/g1195alisa/genotek_wgs/kraken_reports/${filename}_report  --output /home/g1195alisa/kraken_reports/${filename} $f; done`

__Suspicious results: lots of exotic viruses, while cosmopolitan ones are not found: need to use some threshold - Kraken has confidence score option - set 0,65.__

No viruses found in WES samples, which is expected.<br />

### Viral load estimation
На примере HPV<br />
Использованные файлы:
`/home/g1195alisa/GRCh38_2013/GCA_000001405.15_GRCh38_genomic.fna`
`/home/orlov239/data/reference/HPV16_alphaPV9_RefSeq.fna (RefSeq NC_001526, ftp://ftp.ncbi.nlm.nih.gov/genomes/refseq/viral/Alphapapillomavirus_9/latest_assembly_versions/GCF_000863945.3_ViralProj15505)`
`/home/g1195alisa/alignment/alignment_sorted.bam.gz`
`/home/orlov239/data/HPV/processed/F_dedup_tr5.fastq.gz`
`/home/orlov239/data/HPV/processed/R_dedup_tr5.fastq.gz`
Формула для подсчета вирусного титра (количество копий вирусного генома на один клеточный геном): <br />

C=2*(number of reads mapped to virus genome/virus genom size)/(number of reads mapped to human genome/human genome size) <br />
или<br />

C=2*(virus genome coverage/human genome coverage)<br />


__Вариант 1.__ Рассматриваем количество ридов из предобработанных fastq, выровнявшихся на человека или HPV <br />
A) Считаем количество ридов, которые “правильно” выровнялись на человека)

`samtools view -c -q 10 -f 3 -F 2316 -@ 8 /home/g1195alisa/alignment/alignment_sorted.bam.gz`

-q 10 (отсечка по MAPQ>10) <br />
-f 3 (read paired (0x1) and read mapped in proper pair (0x2)) <br />
-F 2316 (read unmapped (0x4), mate unmapped (0x8), not primary alignment (0x100) and supplementary alignment (0x800)) <br />
59,489,753.00  <br />


B) Выравниваем первоначальные fastq файлы на HPV и считаем количество выровнявшихся ридов (MAPQ>10) 

`bwa mem -t 8 /home/orlov239/data/reference/viral_RefSeq/HPV16_alphaPV9_RefSeq.fna /home/orlov239/data/HPV/processed/F_dedup_tr5.fastq.gz` `/home/orlov239/data/HPV/processed/R_dedup_tr5.fastq.gz | samtools view -@ 8 -b | samtools sort -@ 8 -o /home/orlov239/data/HPV/aligned_to_HPV/aligned_to_HPV16.bam`

`samtools view -c -q 10 -f 3 -F 2316 -@ 8 /home/orlov239/data/HPV/aligned_to_HPV/aligned_to_HPV16.bam`
35,629.00 

C= 523.72 <br />

__Вариант 2.__ Выравниваем риды, которые не выровнялись на человека, на HPV<br />

A) Экстрагируем single-end риды, которые не выровнялись на человека 
`samtools fastq -@ 8 -f 4 -F 0x900 /home/g1195alisa/alignment/alignment_sorted.bam.gz > /home/orlov239/data/HPV/unmapped/unmapped_to_GRCh38.fastq`

B) Выравниваем их на HPV и считаем количество выровнявшихся
`bwa mem -t 8 /home/orlov239/data/reference/viral_RefSeq/HPV16_alphaPV9_RefSeq.fna /home/orlov239/data/HPV/unmapped/unmapped_to_GRCh38.fastq | samtools view -@ 10 -b | samtools sort -@ 10 -o` `/home/orlov239/data/HPV/aligned_to_HPV/aligned_to_HPV16_from_unmapped_to_GRCh38.bam`

`samtools view -c -q 10 -F 2308 -@ 8 /home/orlov239/data/HPV/aligned_to_HPV/aligned_to_HPV16_from_unmapped_to_GRCh38.bam`
-F 2308 (read unmapped (0x4), not primary alignment (0x100) and supplementary alignment (0x800))<br />
 7,332.00 <br />

C=  107.77 <br />

__Вариант 3.__ Используем количество ридов, которые Kraken классифицировал как HPV <br />

А) Подаем на вход Kraken то, что не выровнялось на человека
`/home/orlov239//tools/kraken2/kraken2 --fastq-input --use-names --db ./databases/standart --threads 7 --output ~/data/HPV/reports/kraken2/1st_try/kraken_output --classified-out ~/data/HPV/reports/kraken2/1st_try/kraken_output_clssified_seq.fastq --unclassified-out ~/data/HPV/reports/kraken2/1st_try/kraken_output_unclssified_seq.fastq /home/orlov239/data/HPV/unmapped/unmapped_to_GRCh38.fastq`

В) Считаем количество ридов, классифицированных как HPV 
`awk '$1=="C" {print $0}' /home/orlov239/~/data/HPV/reports/kraken2/1st_try/kraken_output | grep -i papillo | cut -f 3 | sort | uniq -c | head`

7,086.00<br />

C=   104.16  <br />

__Варианты 4 и 5.__ Подсчет с использованием среднего или медианного значений покрытия геномов. <br />

Выбор случайных участков человеческого генома для подсчета покрытия<br />

Сначала строим index .bam файла (samtools index)<br />
Создаем файл GRCh38_intervals_4x2000x22.bed, содержащий информацию о длине интервалов и хромосомах, на которых они локализованы в формате:<br />
chr_name	interval_start	interval_end<br />
Важна только длина, но не конкретные значения начала и конца отрезка.<br />

Выбираем случайные интервалы: 
`bedtools shuffle -chrom -noOverlapping -i GRCh38_int_rand_4x2000x22_sort.bed -g ~/data/reference/GRCh38/GRCh38_chrName_chrLen > GRCh38_int_rand_4x2000x22.bed`
Сортируем его:
`sort -k1,1 -k2,2n GRCh38_int_rand_4x2000x22.bed > GRCh38_int_rand_4x2000x22_sort.bed`


Оцениваем медианное покрытие человеческого генома
`bedtools coverage -hist -sorted -a GRCh38_int_rand_4x2000x22_sort.bed -b /home/g1195alisa/alignment/alignment_sorted.bam -g ~/data/reference/GRCh38/GRCh38_chrName_chrLen | grep "all" | awk 'BEGIN {sum=0}; {sum+=$3}; (sum>=$4/2) {print $2; exit}; END {print sum}`
1<br />

Оцениваем среднее покрытие человеческого генома
`samtools depth -a /home/g1195alisa/alignment/alignment_sorted.bam.gz -b GRCh38_intervals.bed | awk 'BEGIN {sum=0; num=0}; {sum+=$3; num+=1}; END {print sum/num}'`
2.10953<br />

Считаем медианное покрытие всего вирусного генома
`bedtools genomecov -ibam /home/orlov239/data/HPV/aligned_to_HPV/aligned_to_HPV16_from_unmapped_to_GRCh38.bam | grep "genome" | awk 'BEGIN {sum=0}; {sum+=$3}; (sum>=4953) {print $2; exit}; END {print sum}'`
94<br />

Считаем среднее покрытие всего вирусного генома
`bedtools genomecov -d -ibam ~/data/HPV/aligned_to_HPV/aligned_to_HPV16_from_unmapped_to_GRCh38.bam | awk 'BEGIN {sum=0; num=0}; {sum+=$3; num+=1}; END {print sum/num}'`
90.5<br />

Cmed=188 <br /> 

Cavr=89.12  <br />

__Все методы, за исключением 1-ого, дали сходные значения.__ <br />

Ввиду его простоты, целесообразно использовать метод №3

__Итак, мы определились с методом подсчета нагрузки, параметрами запуска Кракена и разобрались с парсингом отчетных файлов для получения нужной информации. Далее перед нами стояла задача прогнать наш пайплайн на нескольких европейских популяциях из 1000 Genomes и представить по ним статистические данные подсчета нагрузки и представленности вирусов. Каждая из популяций включала в себя около сотни образцов, пэтому нужно было написать единый цикл, который будет запускать все команды пайплайна на всех образцах, выбирая из каждого образца риды одного запуска секвенатора. Цикл был реализован на bash и находится по ссылке *ссылка*.

## 1000 Genomes:

#### 1. Достаем риды, которые выровнялись на декой последовательности вирусов

`samtools view -h -@ 8 /home/nadya379/1000_genomes_cram/data_cram/CEU/*.low_coverage.cram chrEBV chrUn_JTFH01000690v1_decoy > /home/nadya379/1000_genomes_cram/data_unmapped_bam/*_decoy.bam`

#### 2. Достаем парные риды, которые никуда не выровнялись

`samtools view -h -f 12 -F 256 -@ 8 /home/nadya379/1000_genomes_cram/data_cram/CEU/*low_coverage.cram > /home/nadya379/1000_genomes_cram/data_unmapped_bam/*_unmapped.bam`

#### 3. Сливаем два файла (невыровненные и выровненные на декой)

`samtools merge /home/nadya379/1000_genomes_cram/data_unmapped_bam/*.bam /home/nadya379/1000_genomes_cram/data_unmapped_bam/*_decoy.bam /home/nadya379/1000_genomes_cram/data_unmapped_bam/*_unmapped.bam -@ 8`

#### 4. Конвертируем в парные фаста файлы

`samtools fasta -1 /home/nadya379/1000_genomes_cram/data_paired_fasta/*_1.fasta -2 /home/nadya379/1000_genomes_cram/data_paired_fasta/*_2.fasta -@ 8 /home/nadya379/1000_genomes_cram/data_unmapped_bam/*.bam`

#### 5. Запускаем кракен на парных ридах

`/home/orlov239/tools/kraken2/kraken2 —use-names —db /home/orlov239/tools/kraken2/databases/standart —threads=8 —report /home/nadya379/1000_genomes_cram/kraken_output_report/*_kraken_report —output /home/nadya379/1000_genomes_cram/kraken_output_report/*_kraken_output —confidence 0.65 —paired /home/nadya379/1000_genomes_cram/data_paired_fasta/*_1.fasta /home/nadya379/1000_genomes_cram/data_paired_fasta/*_2.fasta`


Bash-цикл для запуска пайплайна для всех образцов:<br/> 
__запускать нужно из папки с cram-файлами (!)__  

__UPD:__ текущая версия скрипта *ссылка на гитхаб*

### GWAS

#### Подготовка данных для GWAS

vcf-файлы с SNP для 1000 геномов скачаны с ... <br/> 

На основе отчетных фалов Кракена получены таблицы следющего вида: <br/> 
1) sample ID <br/> 
2) population  <br/> 
3) EBV reads <br/> 
4) EBV load  <br/> 

*Для аденовируса, соответственно, adenovirus reads & adenovirus load

Таблицы получали отдельно для каждой популяции, а потом объединяли в одну общую таблицу:

`cat /home/1000_genomes/kraken_output_report/IBS/viral_load_est_general_2019-05-09-Thu.07\:35\:03 | cut -f 2 | uniq | sed 's/^/ IBS\t /' > ids_IBS > TSI_IDs`

`sudo cat viral_load_est_general_2019-05-07-Tue.21\:48\:22  | grep "Human gammaherpesvirus 4" | cut -f 2,9,10 | sed 's/^/ TSI\t /' > TSI_EBV `

`paste TSI_IDs TSI_EBV > EBV_TSI_report`

После исполнения вышеуказанных команд для всех популяций, все файлы сконкатенировали в один: 
`cat EBV_GBR_report EBV_IBS_report EBV_FIN_report EBV_TSI_report_new EBV_TSI_report > EBV_report`


GWAS проводился компанией Genotek с использованием программы __Plink__ <br/> 

__Здесь надо написаь небольшое заключение о том, что мы в итоге получили__